---
title: "BL-CNV analysis, part V"
author: "AG"
date: "`r Sys.Date()`"
format:
  html:
    toc: true
    toc_float: true
    theme: minty
    embed-resources: true
    code-fold: true
    code-summary: "show code"
    df-print: kable
    cap-location: top
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Scheme of the region of interest

Compared to part 2, here I use longer both red and green regions. 
For the red one I will use all available length (1677 bp). 
The green region will have the same length.

![the region](figures/pDA61218-116_long_flanking_regions.png)

## Objective

Here I will outline all the filtering steps that we have decided to include into the pipeline

## Data set

As an example I will use sample `76595_D_mh`

## Filtering 1: minimal length of reads

Keep only reads longer than 1820 nt (500 nt of FR red hit + 820 nt of IS + 500 nt of anything else, possibly FR green)

```{bash}
#| eval: false
# the following line is taken from the snakemake pipline
# input: "results/reads/{sample}/reads_all.fastq.gz"
# output: "results/reads/{sample}/reads_filtered.fastq.gz"
filtlong --min_length {params.min_len} {input} 2> {log} | pigz -c -p {threads} > {output}
```


## Filtering 2: FR red + IS

Keep the reads containing read and IS hits in the same orientation AND within a certain distance

```{r}
parse_blast <- function(file_path, region_name) {
  # read blast table
  df <- read_delim(file_path, col_names = FALSE, show_col_types = FALSE)
  # check if the table is empty
  stopifnot(nrow(df) > 0)
  # check if nrow is wrong
  stopifnot(ncol(df) == 12)
  # assign names
  names(df) <- c("query", "subject", "identity", "length", "mismatch",
                 "gaps", "start.query", "end.query", "start.subject",
                 "end.subject", "e.value", "bit.score")
  # create orientation column
  df$orientation <- ifelse(df$start.subject < df$end.subject, "direct", "reverse") # nolint: line_length_linter.
  # rename query
  df$query <- region_name
  return(df)
}

blast_red <- parse_blast("../results/tables/76595_D_mh/blast_red.tsv", "FR_red")
blast_repunit <- parse_blast("../results/tables/76595_D_mh/blast_repeat_unit.tsv", "Rep_unit")
```

### IS hits length

```{r}
blast_repunit %>% 
  ggplot(aes(length)) +
  geom_histogram(bins = 100) +
  geom_rug()
```

### IS hits per read

```{r}
blast_repunit %>% 
  group_by(subject) %>% 
  count() %>% 
  ggplot(aes(n)) +
  geom_histogram(bins = 50) +
  geom_rug() + 
  ylab("n rep units per read")
```

### Filter the RED and IS hits by quality

```{r}
# NB: min length is different from FR's min length
blast_repunit <- blast_repunit %>%
  filter(length > 700, e.value < 0.00001, identity > 0.75) %>%
  select(query, contains("subject"), orientation)

# FR has different length
blast_red <- blast_red %>%
  filter(length > 500, e.value < 0.00001, identity > 0.75) %>%
  select(query, contains("subject"), orientation)

# join 
# there will be one-to-many matches, apply the 2nd filtering step
# look at the distances between start.subject.x and end.subject.y
# subject.x and subject.y should be close to next after each other 
red_repunit <- left_join(blast_red, blast_repunit, by = 'subject') %>%
  filter(orientation.x == orientation.y) %>% 
  mutate(distance = if_else(orientation.x == "reverse", 
                            end.subject.y - start.subject.x + 1, 
                            start.subject.x - end.subject.y + 1)) 
```


### Distance btw RED and IS 

```{r}
red_repunit %>% 
  ggplot(aes(distance)) +
  geom_histogram(bins = 100) +
  geom_rug()
```

```{r}
tibble(
  stat = names(summary(red_repunit$distance)), 
  value = as.numeric(summary(red_repunit$distance))
)
```

### Minimal distance in each read

```{r}
red_repunit %>% 
  group_by(subject) %>% 
  mutate(min_dist = min(abs(distance))) %>% 
  select(subject, min_dist) %>% 
  distinct() %>% 
  ggplot(aes(min_dist)) +
  geom_histogram(bins=100) +
  geom_rug()
```

```{r}
red_repunit %>% 
  group_by(subject) %>% 
  mutate(min_dist = min(abs(distance))) %>% 
  select(subject, min_dist) %>% 
  distinct() %>%
  pull(min_dist) %>% 
  summary()
```

### Apply distance filter

Optimal distance cut-off

```{r}
distance_filter <- function(max_distance, df){
  # unique reads only
  length(unique(filter(df, distance <= max_distance) %>% pull(subject)))
}

tibble(
  max.dist = seq(0, 100, 1), 
  n.reads = map_int(
    seq(0, 100, 1), ~ distance_filter(., red_repunit)
    )) %>%
  ggplot(aes(max.dist, n.reads)) +
  geom_point() +
  scale_x_continuous(breaks = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100))
         
```

Let's use `max.distance = 30`

```{r}
max_dist <- 30

red_repunit_dir_dist <- red_repunit %>% 
  filter(distance <= max_dist)

nrow(red_repunit_dir_dist)
```

```{r}
# give this table nicer names
# keep only columns that are needed
red_repunit_dir_dist <- 
  red_repunit_dir_dist %>% 
  select(subject, start.subject.x, end.subject.x, start.subject.y, end.subject.y, distance, orientation.x)

names(red_repunit_dir_dist) <- c("subject", "start.red", "end.red", "start.rep.unit", "end.rep.unit", "dist", "orient")

head(red_repunit_dir_dist)
```

## Filtering 3: FR + IS + 1820/5270/8720 etc towards the repeats

Keep the reads containing RED and IS in the same orientation AND at least 1820 (500 + 820 + 500) from the start of the RED towards the repeats (IS).

i.e.: 

- if direct: keep if `end.red` > 1820

- if reverse: keep if `start.rep.unit` > 1820

Check it out here:

```{r}
# if direct: keep if end.subject.x > 1820
# if reverse: keep if start.subject.y > 1820
red_repunit_dir_dist %>% 
  filter(orient == "direct") %>% 
  #select(-orientation.y) %>% 
  #arrange(read.len) %>% 
  head()
```

```{r}
red_repunit_dir_dist %>% 
  filter(orient == "reverse") %>% 
  #select(-orientation.y) %>%
  #arrange(read.len) %>% 
  head()
```

### Filtering itself

```{r}
red_repunit_dir_dist_len <-
  red_repunit_dir_dist %>%
  mutate(keep = if_else(
    orient == "direct",
    end.red > 1820,
    start.rep.unit > 1820
  )) %>%
  filter(keep)

nrow(red_repunit_dir_dist_len)
```


Which is `r nrow(red_repunit_dir_dist_len)/nrow(red_repunit_dir_dist)` of the previous filtering

```{r}
head(red_repunit_dir_dist_len)
```

## Read counts in bins

Having just a distribution of lengths is not enough

We need bins (i.e. number of reads in each bin) of reads:
 - able to contain 0 blaSHV copies (all reads)
 - able to contain 1 blaSHV copy (min length of 5270 bp from the beginning of RED towards RU)
 - able to contain 2 bla SHV copies (min len. 8720...)
 
 and so on
 
 
If the hit is direct, then `red.end` > (1820+3450*CN)  is enough
If the hit is reverse, then I need the distance between `red.end` and the opposite end of this read, which is `read.length` - `red.end`, in other words: (`read.length` - `red.end`) > (1820+3450*CN)

```{r}
library(tidyverse)

# read the table with reads filtered by red fr + rep.unit + orientation
table_path <- "../results/tables/76595_D_mh/blast_joined_red_repunit_orient_len.tsv"

blast_df <- read_tsv(
  file = table_path, 
  show_col_types = FALSE
  )

# filter direct hits
blast_df_direct <- 
  blast_df %>% 
  filter(orient == "direct")
# filter those that have the required distance
# here's a function
count_reads_with_cn <- function(df, cn = 0) {
  # only for direct hits!
  df %>%
    mutate(keep = end.red > (1820 + 3450 * cn)) %>%
    filter(keep) %>% 
    nrow()
}
# let's consider up to 12 copies
number_of_copies <- seq(0, 12, 1)
# apply the function above
n_reads_w_cn_direct <-
  data.frame("CN" = number_of_copies,
             "n.reads" = map_int(
               number_of_copies,
               ~ count_reads_with_cn(blast_df_direct, cn = .)
             ))

#### now do different kind of filtering/counting using reverse reads ####
# these are the reads after the 1st filtering by length
reads_path <- "../results/reads/76595_D_mh/reads_filtered.fasta"
read_lengths <-
  Biostrings::width(Biostrings::readDNAStringSet(reads_path))

reads_len_df <-
  tibble("subject" = sub(
    "^(.*?) runid=.*",
    "\\1",
    names(Biostrings::readDNAStringSet(reads_path))
  ),
  "read.len" = read_lengths)

# filter reverse reads and
# join with reads lengths
blast_df_reverse <- 
  blast_df %>% 
  filter(orient == "reverse") %>% 
  left_join(reads_len_df, by = "subject")

# function to get the counts
count_reads_with_cn_reverse <- function(df, cn = 0) {
  # only for reverse hits!
  df %>%
    mutate(keep = (read.len - end.red) > (1820 + 3450 * cn)) %>%
    filter(keep) %>% 
    nrow()
}

# apply it
n_reads_w_cn_reverse <-
  data.frame("CN" = number_of_copies,
             "n.reads" = map_int(
               number_of_copies,
               ~ count_reads_with_cn_reverse(blast_df_reverse, cn = .)
             ))

n_reads_w_cn <- full_join(n_reads_w_cn_direct, n_reads_w_cn_reverse, by = "CN") %>% 
  mutate(n.reads.total = n.reads.x + n.reads.y)

write_delim(n_reads_w_cn, file = "../results/tables/76595_D_mh/number_reads_containing_CN.tsv")

n_reads_w_cn
```


```{r}
n_reads_w_cn %>% 
  ggplot(aes(CN, n.reads.total)) +
  geom_col(fill="darkgreen", alpha = 0.5)
```



## Test of compatibility

New filtering of FR+RU+1820 and old FR green blast table

```{r}
get_multihits_ids <- function(df) {
  # df: filtered blast table
  # return: subject (read ids) containing multiple query hits
  df %>%
    group_by(subject) %>%
    count() %>%
    filter(n > 1) %>%
    pull(subject)
}

# here's the updated filtering function
filter_red_green <- function(df_red_ru, df_green) {
  # find read IDs containing multiple query hits
  reads_multiple_hits <- union(get_multihits_ids(df_red_ru),
                               get_multihits_ids(df_green))
  # filter out reads with multiple query hits
  # df_red_ru have differen column names!
  df_red_ru_filt <- df_red_ru %>%
    filter(!subject %in% reads_multiple_hits)
  df_green_filt <- df_green %>%
    filter(!subject %in% reads_multiple_hits)
  
  # Filter by orientation
  # Add distance between FRs
  df_joined <- full_join(df_red_ru_filt, df_green_filt, by = "subject") %>%
    filter(!is.na(query.x), !is.na(query.y), orient == orientation) %>%
    mutate(green.red.distance = end.red - start.subject,
           distance.btw.FR = if_else(green.red.distance < 0, 
                                     green.red.distance * -1, 
                                     green.red.distance * 1))
  return(df_joined)
}

blast_green <- parse_blast(file = "../results/tables/76595_D_mh/blast_green.tsv", "FR_green")
blast_red <- red_repunit_dir_dist
blast_red$query <- "FR_RU_filt"

# test the function
filter_red_green(blast_red, blast_green)
# it works!
```

## Calculations: way no. 1

reads that have passed through filtering step no. 3: R + IS + orient + 1820 incl.R

```{r}
library(tidyverse)

file_path <- "../results/tables/76595_D_mh/blast_joined_red_repunit_orient_len.tsv"

df_f3 <- read_tsv(file_path, show_col_types = F)

head(df_f3)
```

unique reads

```{r}
length(unique(df_f3$subject))
```

For the actual calculations see the Excel file

Binned reads: number of reads capable of containing certain number of blaSHV copies

```{r}
file <- "../results/tables/76595_D_mh/number_reads_containing_CN.tsv"

cn_bins <- read_delim(file, show_col_types = F) %>% 
  select(CN, n.reads.total) %>% 
  rename("reads_counts_theor" = n.reads.total)

cn_bins
```

Now I need reads that actually contain 0, 1, 2 etc copies of blaSHV


```{r}
# the last table produced by the pipeline - with blaSHV counts
file <- "../results/tables/76595_D_mh/blaSHV_counts.tsv"
bla_cn <- read_delim(file, show_col_types = F) %>% 
  filter(!is.na(n.blaSHV.merged)) # why do you have NAs there?

unique(bla_cn$n.blaSHV.merged)
```


How many reads that were input of this step (i.e. from step 3) did not have any blaSHV?

```{r}
length(unique(df_f3$subject)) - length(unique(bla_cn$subject))
```

How many had different number of blaSHV copies?

```{r}
cn0 <- length(unique(df_f3$subject)) - length(unique(bla_cn$subject))

bla_cn_freq <- 
  bla_cn %>% 
  group_by(n.blaSHV.merged) %>% 
  count(name = "counts") %>% 
  ungroup() %>% 
  mutate(counts = counts + c(cn0, rep(0, 9))) %>% 
  rename("CN" = n.blaSHV.merged,
         "bla_counts_obs" = counts)

bla_cn_freq
```

Calculation of the final table from the Excel file

```{r}
# total - n reads with 0 CN from the cn_bins table
total <- cn_bins %>% 
  filter(CN == 0) %>% 
  pull(reads_counts_theor)

# find observed CN frequency
bla_cn_freq <- 
  bla_cn_freq %>% 
  mutate(bla_freq_obs = bla_counts_obs / total)

# find frequency of reads that might contain certain CN
cn_bins <- 
  cn_bins %>% 
  mutate(bla_freq_theor = reads_counts_theor / total)

# adjust CN counts and then calculate frequency
bla_cn_freq <- 
  bla_cn_freq %>% 
  left_join(cn_bins, by = "CN") %>% 
  mutate(bla_counts_adj = bla_counts_obs / bla_freq_theor,
         bla_freq_adj = bla_counts_adj/sum(bla_counts_adj))

bla_cn_freq
```

```{r}
sum(bla_cn_freq$bla_freq_adj)
```


### Plot

```{r, fig.width=10, fig.height=10}
library(patchwork)

plot_line_full <- bla_cn_freq %>%
  select(CN, bla_freq_obs, bla_freq_adj) %>%
  pivot_longer(cols = 2:3,
               names_to = "group",
               values_to = "freq") %>%
  ggplot(aes(CN, freq)) +
  geom_line(aes(color = group)) +
  scale_x_continuous(breaks = c(0:12)) +
  geom_rug(sides = "b", length = unit(0.03, "npc")) +
  scale_color_brewer(palette = "Dark2") +
  theme_bw() +
  theme(legend.position="top", legend.title = element_blank())

plot_line_part <- bla_cn_freq %>% 
  select(CN, bla_freq_obs, bla_freq_adj) %>% 
  filter(CN >= 5) %>% 
  pivot_longer(cols = 2:3, names_to = "group", values_to = "freq") %>% 
  ggplot(aes(CN, freq)) + 
  geom_line(aes(color = group)) +
  scale_x_continuous(breaks = c(0:12)) +
  geom_rug(sides = "b", length = unit(0.03, "npc")) +
  scale_color_brewer(palette = "Dark2") +
  theme_bw() +
  theme(legend.position="top", legend.title = element_blank())

plot_line_log10 <- bla_cn_freq %>%
  select(CN, bla_freq_obs, bla_freq_adj) %>%
  pivot_longer(cols = 2:3,
               names_to = "group",
               values_to = "freq") %>%
  ggplot(aes(CN, log10(freq))) +
  geom_line(aes(color = group)) +
  scale_x_continuous(breaks = c(0:12)) +
  geom_rug(sides = "b", length = unit(0.03, "npc")) +
  scale_color_brewer(palette = "Dark2") +
  theme_bw() +
  theme(legend.position="top", legend.title = element_blank())

(plot_line_full | plot_line_part) / plot_line_log10
```


```{r, fig.width=10}
plot_col_full <- bla_cn_freq %>% 
  select(CN, bla_freq_obs, bla_freq_adj) %>% 
  pivot_longer(cols = 2:3, names_to = "group", values_to = "freq") %>% 
  ggplot(aes(CN, freq)) + 
  geom_col(aes(fill = group), position = "dodge") +
  scale_fill_brewer(palette = "Dark2") +
  scale_x_continuous(breaks = c(0:12)) +
  theme_bw() +
  geom_rug(sides = "b", length = unit(0.03, "npc")) + 
  theme(legend.position="top", legend.title = element_blank())

plot_col_part <- bla_cn_freq %>% 
  select(CN, bla_freq_obs, bla_freq_adj) %>% 
  filter(CN >= 5) %>% 
  pivot_longer(cols = 2:3, names_to = "group", values_to = "freq") %>% 
  ggplot(aes(CN, freq)) + 
  geom_col(aes(fill = group), position = "dodge") +
  scale_fill_brewer(palette = "Dark2") +
  scale_x_continuous(breaks = c(0:12)) +
  theme_bw() +
  geom_rug(sides = "b", length = unit(0.03, "npc")) + 
  theme(legend.position="top", legend.title = element_blank())

(plot_col_full | plot_col_part)
```

## Calculations: way no. 2

We take into consideration only the reads that can contains the biggest CN of bla genes and calculate CN frequencies.
This new distribution should look similar to the one above.


```{r}
# this function returns a table of reads possibly containing 
# specified number of bla genes
# input: a table with direct hist and a table with reverse hits + corresponding reads lengths
reads_with_cn <- function(df_dir, df_rev, cn = 0) {
  min_len <- (1820 + 3450 * cn)
  bind_rows(
    # only for direct hits!
    df_dir %>%
      mutate(keep = end.red > min_len) %>%
      filter(keep),
    # only for reverse hits!
    df_rev %>%
      mutate(keep = (read.len - end.red) > min_len) %>%
      filter(keep)
  )
}

# biggest CN is 11
reads_cn11 <- reads_with_cn(blast_df_direct, blast_df_reverse, cn = 11) %>% 
  left_join(bla_cn, by = "subject") %>% 
  select(-c(keep, read.len))

# some reads do not contain blaSHV as expected
reads_cn11 %>% filter(is.na(n.blaSHV.merged)) %>% nrow()

# observed bla counts
reads_cn11 %>% 
  filter(!is.na(n.blaSHV.merged)) %>% 
  ggplot(aes(n.blaSHV.merged)) +
  geom_histogram(binwidth = 1) +
  scale_x_continuous(breaks = c(0:12)) +
  theme_bw() +
  geom_rug(sides = "b", length = unit(0.03, "npc"))
```

Get the actual frequencies

```{r}
reads_cn11_freq <- reads_cn11 %>% 
  filter(!is.na(n.blaSHV.merged)) %>% 
  select(subject, n.blaSHV.merged) %>% 
  group_by(n.blaSHV.merged) %>% 
  count() %>% 
  ungroup() %>% 
  mutate(freq_by_longest = n/sum(n)) %>% 
  rename("CN" = n.blaSHV.merged)

reads_cn11_freq %>% 
  ggplot(aes(CN, freq_by_longest)) +
  geom_line() +
  scale_x_continuous(breaks = c(0:12)) +
  theme_bw() +
  geom_rug(sides = "b", length = unit(0.03, "npc"))
  
```

Compare with the other way of calculating bla CN frequency

```{r}
bla_freq_2ways <-
  full_join(bla_cn_freq %>%
              select(CN, bla_freq_obs, bla_freq_adj),
            reads_cn11_freq %>% 
              select(-n),
            by = "CN") %>% 
  mutate(freq_by_longest = map_dbl(freq_by_longest, ~replace(., is.na(.), 0)))

bla_freq_2ways %>% 
  pivot_longer(cols = 2:4,
               names_to = "group",
               values_to = "frequency") %>%
  ggplot(aes(CN, log10(frequency))) +
  geom_line(aes(color = group)) +
  scale_x_continuous(breaks = c(0:8, 11)) +
  geom_rug(sides = "b", length = unit(0.03, "npc")) +
  scale_color_brewer(palette = "Dark2") +
  theme_bw() +
  theme(legend.position="top", legend.title = element_blank())
```


```{r}
bla_freq_2ways
```

