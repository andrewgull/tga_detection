__author__ = "Andrei Guliaev"
__copyright__ = "Copyright 2024, Andrei Guliaev"
__email__ = "andrei.guliaev@scilifelab.uu.se"
__license__ = "GPL-3"

from snakemake.io import expand, directory, touch, temp
from scripts.utils import get_sample_path, tsv2dict
import pandas as pd


# read strain names
sample_table = pd.read_csv(config["sample_table"], sep="\t", dtype={"sample": str, "path": str})

# read parameters into a dictionary
parameters = tsv2dict(config["parameters"])

#### Rules ####

rule all:
    input:
        expand("results/final/{sample}_all.done", sample=sample_table["sample"]),
        f"{config['output_name']}.tsv",


# filter reads by length
rule filter_reads:
    input:
        lambda wildcards: get_sample_path(wildcards, sample_table),
    output:
        temp("results/reads_filtered/{sample}_filtered.fastq.gz"),
    threads: 8
    log:
        "results/logs/{sample}_filtlong.log",
    conda:
        "envs/filtlong.yaml"
    params:
        min_len=parameters["min_read_len"],
    shell:
        "filtlong --min_length {params.min_len} {input} 2> {log} | pigz -c -p {threads} > {output}"


# convert fastq to fasta
rule fq2fasta:
    input:
        "results/reads_filtered/{sample}_filtered.fastq.gz",
    output:
        "results/reads_filtered/{sample}_filtered.fasta.gz",
    threads: 4
    log:
        "results/logs/{sample}_seqkit_fq2fa.log",
    conda:
        "envs/seqkit.yaml"
    shell:
        "seqkit fq2fa -j {threads} {input} | pigz -c -p {threads} 1> {output} 2> {log}"


# cut flanking regions Red (RR) from plasmid
rule create_fr_red:
    input:
        config["plasmid"],
    output:
        "results/flanking_regions/fr_red.fa",
    threads: 4
    log:
        "results/logs/seqkit_subseq_fr_red.log",
    conda:
        "envs/seqkit.yaml"
    params:
        start=parameters["fr_red_start"],
        end=parameters["fr_red_end"],
    shell:
        "seqkit subseq -r {params.start}:{params.end} {input} 1> {output} 2> {log}"


# cut flanking region Green (GR) from plasmid
rule create_fr_green:
    input:
        config["plasmid"],
    output:
        "results/flanking_regions/fr_green.fa",
    threads: 4
    log:
        "results/logs/seqkit_subseq_fr_green.log",
    conda:
        "envs/seqkit.yaml"
    params:
        start=parameters["fr_green_start"],
        end=parameters["fr_green_end"],
    shell:
        "seqkit subseq -j {threads} -r {params.start}:{params.end} {input} 1> {output} 2> {log}"


# blast DB of reads
rule make_blast_db:
    input:
        "results/reads_filtered/{sample}_filtered.fasta.gz",
    output:
        directory("results/blast_databases/{sample}"),
    threads: 8
    log:
        "results/logs/{sample}_blastdb.log",
    conda:
        "envs/blast.yaml"
    shell:
        "pigz -c -d -p {threads} {input} | makeblastdb -in - -dbtype nucl -title blastdb -out {output}/blastdb &> {log}"


# search for RR
rule blast_red:
    input:
        query="results/flanking_regions/fr_red.fa",
        database="results/blast_databases/{sample}",
    output:
        "results/tables/{sample}/blast_red.tsv",
    threads: 8
    params:
        fmt=parameters["format"],
        n_alns=parameters["n_fr_aligns"],
    log:
        "results/logs/{sample}_blast_red.log",
    conda:
        "envs/blast.yaml"
    shell:
        "blastn -query {input.query} -db {input.database}/blastdb -outfmt {params.fmt} "
        "-num_threads {threads} -num_alignments {params.n_alns} 1> {output} 2> {log}"


# search for GR
rule blast_green:
    input:
        query="results/flanking_regions/fr_green.fa",
        database="results/blast_databases/{sample}",
    output:
        "results/tables/{sample}/blast_green.tsv",
    threads: 8
    params:
        fmt=parameters["format"],
        n_alns=parameters["n_fr_aligns"],
    log:
        "results/logs/{sample}_blast_green.log",
    conda:
        "envs/blast.yaml"
    shell:
        "blastn -query {input.query} -db {input.database}/blastdb -outfmt {params.fmt} "
        "-num_threads {threads} -num_alignments {params.n_alns} 1> {output} 2> {log}"


# cut repeat unit (RU) from plasmid
rule create_repeat_unit:
    input:
        config["plasmid"],
    output:
        "results/flanking_regions/repeat_unit.fa",
    log:
        "results/logs/seqkit_repunit.log",
    params:
        start=parameters["ru_start"],
        end=parameters["ru_end"],
    conda:
        "envs/seqkit.yaml"
    shell:
        "seqkit subseq -r {params.start}:{params.end} {input} 1> {output} 2> {log}"


# search for RU
rule blast_repeat_unit:
    input:
        query="results/flanking_regions/repeat_unit.fa",
        database="results/blast_databases/{sample}",
    output:
        "results/tables/{sample}/blast_repeat_unit.tsv",
    threads: 8
    log:
        "results/logs/{sample}_blast_repeat_unit.log",
    conda:
        "envs/blast.yaml"
    params:
        fmt=parameters["format"],
        n_alns=parameters["n_bla_aligns"],
    shell:
        "blastn -query {input.query} -db {input.database}/blastdb -outfmt {params.fmt} "
        "-num_threads {threads} -num_alignments {params.n_alns} 1> {output} 2> {log}"


# filter blast hits by RR and RU presence
# RR first and RU right after it (within max dist)
rule filter_rr_ru_blast:
    input:
        red="results/tables/{sample}/blast_red.tsv",
        repunit="results/tables/{sample}/blast_repeat_unit.tsv",
    output:
        "results/tables/{sample}/blast_joined_red_repunit.tsv",
    log:
        "results/logs/{sample}_blast_joined.log",
    conda:
        "envs/rscripts.yaml"
    params:
        identity=parameters["min_identity"],
        e_val=parameters["max_e_value"],
        length_fr=parameters["min_fr_len"],
        length_ru=parameters["min_ru_len"],
        distance=parameters["max_dist"],
    script:
        "scripts/filter_red_repunit.R"


# filter hits by presence of RR and RU in correct orientation,
# distance and at least 1320 nt from the beginning of the RR
rule filter_min_orient_length:
    input:
        "results/tables/{sample}/blast_joined_red_repunit.tsv",
    output:
        "results/tables/{sample}/blast_joined_red_repunit_orient_len.tsv",
    log:
        "results/logs/{sample}_filt_min_orient_len.log",
    conda:
        "envs/rscripts.yaml"
    params:
        dist_to_end=parameters["dist_to_end"],
    script:
        "scripts/filter_by_distance_to_end.R"


# count reads theoretically capable of containing each CN variant
rule cn_reads_bins:
    input:
        table="results/tables/{sample}/blast_joined_red_repunit_orient_len.tsv",
        reads="results/reads_filtered/{sample}_filtered.fasta.gz",
    output:
        "results/tables/{sample}/number_reads_containing_CN.tsv",
    log:
        "results/logs/{sample}_cn_reads_bins.log",
    conda:
        "envs/biostrings.yaml"
    params:
        max_cn=parameters["max_cn"],
        incr=parameters["increment"],
        dist_to_end=parameters["dist_to_end"],
    script:
        "scripts/get_cn_read_counts.R"


# filter GR
# join GR hits with the filtered ones
# from the previous step
rule filter_flanking_regions:
    input:
        red_ru="results/tables/{sample}/blast_joined_red_repunit_orient_len.tsv",
        green="results/tables/{sample}/blast_green.tsv",
    output:
        "results/tables/{sample}/blast_joined.tsv",
    log:
        "results/logs/{sample}_blast_joined.log",
    conda:
        "envs/rscripts.yaml"
    params:
        identity=parameters["min_identity"],
        e_val=parameters["max_e_value"],
        length=parameters["min_fr_len"],
    script:
        "scripts/filter_fr_hits.R"


# search gene
rule blast_blaSHV:
    input:
        query=config["blaSHV"],
        database="results/blast_databases/{sample}",
    output:
        "results/tables/{sample}/blast_blaSHV.tsv",
    threads: 8
    log:
        "results/logs/{sample}_blast_blaSHV.log",
    conda:
        "envs/blast.yaml"
    params:
        fmt=parameters["format"],
        n_alns=parameters["n_bla_aligns"],
    shell:
        "blastn -query {input.query} -db {input.database}/blastdb -outfmt {params.fmt} "
        "-num_threads {threads} -num_alignments {params.n_alns} 1> {output} 2> {log}"


# filter gene hits by joining them with
# the GR & RR hits from previous steps
# and removing aberrant reads
rule filter_blaSHV_hits:
    input:
        bla="results/tables/{sample}/blast_blaSHV.tsv",
        fr="results/tables/{sample}/blast_joined.tsv",
    output:
        "results/tables/{sample}/blast_blaSHV_filtered.tsv",
    log:
        "results/logs/{sample}_blast_blaSHV_filter.log",
    conda:
        "envs/rscripts.yaml"
    params:
        e_val=parameters["max_e_value"],
    script:
        "scripts/filter_gene_blast.R"


# convert filtered gene hits table to BED
rule make_bed_blaSHV_filtered:
    input:
        "results/tables/{sample}/blast_blaSHV_filtered.tsv",
    output:
        "results/bedfiles/{sample}/blaSHV_hits.bed",
    log:
        "results/logs/{sample}_make_bed.log",
    conda:
        "envs/rscripts.yaml"
    script:
        "scripts/make_bed.R"


# merge close gene hits
rule merge_blaSHV_filtered:
    input:
        "results/bedfiles/{sample}/blaSHV_hits.bed",
    output:
        sorted="results/bedfiles/{sample}/blaSHV_hits_sorted.bed",
        merged="results/bedfiles/{sample}/blaSHV_hits_merged.bed",
    log:
        "results/logs/{sample}_bedtools_merge.log",
    conda:
        "envs/bedtools.yaml"
    params:
        dist=parameters["dist"],
    shell:
        "sort -k1,1 -k2,2n {input} > {output.sorted} && "
        "bedtools merge -i {output.sorted} -s -d {params.dist} > {output.merged} 2> {log}"


# count genes in the filtered reads
rule blaSHV_counts:
    input:
        bed="results/bedfiles/{sample}/blaSHV_hits_merged.bed",
        blast="results/tables/{sample}/blast_joined.tsv",
    output:
        "results/tables/{sample}/blaSHV_counts.tsv",
    log:
        "results/logs/{sample}_blaSHV_counts.log",
    conda:
        "envs/rscripts.yaml"
    params:
        length=parameters["bla_len"],
    script:
        "scripts/count_merged_gene_hits.R"


# filter reads by distance between FR
rule filter_by_distance_between_FR:
    input:
        fr="results/tables/{sample}/blast_joined.tsv",
        bla="results/tables/{sample}/blaSHV_counts.tsv",
    output:
        "results/tables/{sample}/blaSHV_counts_filtered.tsv",
    log:
        "results/logs/{sample}_filter_by_distance_between_FR.log",
    conda:
        "envs/rscripts.yaml"
    params:
        base=parameters["base_len"],
        ru_len=parameters["increment"],
    script:
        "scripts/filter_by_distance_between_fr.R"


# calculate observed, expected frequencies etc
rule frequency_calculation:
    input:
        bins="results/tables/{sample}/number_reads_containing_CN.tsv",
        bla="results/tables/{sample}/blaSHV_counts_filtered.tsv",
    output:
        "results/tables/{sample}/frequencies.tsv",
    log:
        "results/logs/{sample}_frequencies.log",
    conda:
        "envs/rscripts.yaml"
    script:
        "scripts/final_calculations.R"


# join samples' tables together
rule aggregate_freq_tables:
    input:
        expand("results/tables/{sample}/frequencies.tsv", sample=sample_table["sample"]),
    output:
        tsv=f"{config['output_name']}.tsv",
        xlsx=f"{config['output_name']}.xlsx",
    log:
        "results/logs/aggregate_freq_tables.log",
    conda:
        "envs/pandas.yaml"
    script:
        "scripts/aggregate_frequency_tables.py"


rule final:
    input:
        freqs="results/tables/{sample}/frequencies.tsv",
    output:
        touch("results/final/{sample}_all.done"),
    log:
        "results/logs/{sample}_final.log",
    shell:
        "echo 'DONE'"


onsuccess:
    print("Workflow finished, no errors")
