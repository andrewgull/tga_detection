---
title: "BL-CNV analysis, part V"
author: "AG"
date: "`r Sys.Date()`"
format:
  html:
    toc: true
    toc_float: true
    theme: minty
    embed-resources: true
    code-fold: true
    code-summary: "show code"
    df-print: kable
    cap-location: top
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Scheme of the region of interest

Compared to part 2, here I use longer both red and green regions. 
For the red one I will use all available length (1677 bp). 
The green region will have the same length.

![the region](figures/pDA61218-116_long_flanking_regions.png)

## Objective

Here I will outline all the filtering steps that we have decided to include into the pipeline

## Data set

As an example I will use sample `76595_D_mh`

## Filtering 1: minimal length of reads

Keep only reads longer than 1820 nt (500 nt of FR red hit + 820 nt of IS + 500 nt of anything else, possibly FR green)

```{bash}
#| eval: false
# the following line is taken from the snakemake pipline
# input: "results/reads/{sample}/reads_all.fastq.gz"
# output: "results/reads/{sample}/reads_filtered.fastq.gz"
filtlong --min_length {params.min_len} {input} 2> {log} | pigz -c -p {threads} > {output}
```


## Filtering 2: FR red + IS

Keep the reads containing read and IS hits in the same orientation AND within a certain distance

```{r}
parse_blast <- function(file_path, region_name) {
  # read blast table
  df <- read_delim(file_path, col_names = FALSE, show_col_types = FALSE)
  # check if the table is empty
  stopifnot(nrow(df) > 0)
  # check if nrow is wrong
  stopifnot(ncol(df) == 12)
  # assign names
  names(df) <- c("query", "subject", "identity", "length", "mismatch",
                 "gaps", "start.query", "end.query", "start.subject",
                 "end.subject", "e.value", "bit.score")
  # create orientation column
  df$orientation <- ifelse(df$start.subject < df$end.subject, "direct", "reverse") # nolint: line_length_linter.
  # rename query
  df$query <- region_name
  return(df)
}

blast_red <- parse_blast("../results/tables/76595_D_mh/blast_red.tsv", "FR_red")
blast_repunit <- parse_blast("../results/tables/76595_D_mh/blast_repeat_unit.tsv", "Rep_unit")
```

### IS hits length

```{r}
blast_repunit %>% 
  ggplot(aes(length)) +
  geom_histogram(bins = 100) +
  geom_rug()
```

### IS hits per read

```{r}
blast_repunit %>% 
  group_by(subject) %>% 
  count() %>% 
  ggplot(aes(n)) +
  geom_histogram(bins = 50) +
  geom_rug() + 
  ylab("n rep units per read")
```

### Filter the RED and IS hits by quality

```{r}
# NB: min length is different from FR's min length
blast_repunit <- blast_repunit %>%
  filter(length > 700, e.value < 0.00001, identity > 0.75) %>%
  select(query, contains("subject"), orientation)

# FR has different length
blast_red <- blast_red %>%
  filter(length > 500, e.value < 0.00001, identity > 0.75) %>%
  select(query, contains("subject"), orientation)

# join 
# there will be one-to-many matches, apply the 2nd filtering step
# look at the distances between start.subject.x and end.subject.y
# subject.x and subject.y should be close to next after each other 
red_repunit <- left_join(blast_red, blast_repunit, by = 'subject') %>%
  filter(orientation.x == orientation.y) %>% 
  mutate(distance = if_else(orientation.x == "reverse", 
                            end.subject.y - start.subject.x + 1, 
                            start.subject.x - end.subject.y + 1)) 
```


### Distance btw RED and IS 

```{r}
red_repunit %>% 
  ggplot(aes(distance)) +
  geom_histogram(bins = 100) +
  geom_rug()
```

```{r}
tibble(
  stat = names(summary(red_repunit$distance)), 
  value = as.numeric(summary(red_repunit$distance))
)
```

### Minimal distance in each read

```{r}
red_repunit %>% 
  group_by(subject) %>% 
  mutate(min_dist = min(abs(distance))) %>% 
  select(subject, min_dist) %>% 
  distinct() %>% 
  ggplot(aes(min_dist)) +
  geom_histogram(bins=100) +
  geom_rug()
```

```{r}
red_repunit %>% 
  group_by(subject) %>% 
  mutate(min_dist = min(abs(distance))) %>% 
  select(subject, min_dist) %>% 
  distinct() %>%
  pull(min_dist) %>% 
  summary()
```

### Apply distance filter

Optimal distance cut-off

```{r}
distance_filter <- function(max_distance, df){
  # unique reads only
  length(unique(filter(df, distance <= max_distance) %>% pull(subject)))
}

tibble(
  max.dist = seq(0, 100, 1), 
  n.reads = map_int(
    seq(0, 100, 1), ~ distance_filter(., red_repunit)
    )) %>%
  ggplot(aes(max.dist, n.reads)) +
  geom_point() +
  scale_x_continuous(breaks = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100))
         
```

Let's use `max.distance = 30`

```{r}
max_dist <- 30

red_repunit_dir_dist <- red_repunit %>% 
  filter(distance <= max_dist)

nrow(red_repunit_dir_dist)
```

```{r}
# give this table nicer names
# keep only columns that are needed
red_repunit_dir_dist <- 
  red_repunit_dir_dist %>% 
  select(subject, start.subject.x, end.subject.x, start.subject.y, end.subject.y, distance, orientation.x)

names(red_repunit_dir_dist) <- c("subject", "start.red", "end.red", "start.rep.unit", "end.rep.unit", "dist", "orient")

head(red_repunit_dir_dist)
```

## Filtering 3: FR + IS + 1820/5270/8720 etc towards the repeats

Keep the reads containing RED and IS in the same orientation AND at least 1820 (500 + 820 + 500) from the start of the RED towards the repeats (IS).

i.e.: 

- if direct: keep if `end.red` > 1820

- if reverse: keep if `start.rep.unit` > 1820

Check it out here:

```{r}
# if direct: keep if end.subject.x > 1820
# if reverse: keep if start.subject.y > 1820
red_repunit_dir_dist %>% 
  filter(orient == "direct") %>% 
  #select(-orientation.y) %>% 
  #arrange(read.len) %>% 
  head()
```

```{r}
red_repunit_dir_dist %>% 
  filter(orient == "reverse") %>% 
  #select(-orientation.y) %>%
  #arrange(read.len) %>% 
  head()
```

### Filtering itself

```{r}
red_repunit_dir_dist_len <-
  red_repunit_dir_dist %>%
  mutate(keep = if_else(
    orient == "direct",
    end.red > 1820,
    start.rep.unit > 1820
  )) %>%
  filter(keep)

nrow(red_repunit_dir_dist_len)
```


Which is `r nrow(red_repunit_dir_dist_len)/nrow(red_repunit_dir_dist)` of the previous filtering

```{r}
head(red_repunit_dir_dist_len)
```

## Read counts in bins

Having just a distribution of lengths is not enough

We need bins (i.e. number of reads in each bin) of reads:
 - able to contain 0 blaSHV copies (all reads)
 - able to contain 1 blaSHV copy (min length of 5270 bp from the beginning of RED towards RU)
 - able to contain 2 bla SHV copies (min len. 8720...)
 
 and so on
 
 
If the hit is direct, then `red.end` > (1820+3450*CN)  is enough
If the hit is reverse, then I need the distance between `red.end` and the opposite end of this read, which is `read.length` - `red.end`, in other words: (`read.length` - `red.end`) > (1820+3450*CN)

```{r}
library(tidyverse)

# read the table with reads filtered by red fr + rep.unit + orientation
table_path <- "../results/tables/76595_D_mh/blast_joined_red_repunit_orient_len.tsv"

blast_df <- read_tsv(
  file = table_path, 
  show_col_types = FALSE
  )

# filter direct hits
blast_df_direct <- 
  blast_df %>% 
  filter(orient == "direct")
# filter those that have the required distance
# here's a function
count_reads_with_cn <- function(df, cn = 0) {
  # only for direct hits!
  df %>%
    mutate(keep = end.red > (1820 + 3450 * cn)) %>%
    filter(keep) %>% 
    nrow()
}
# let's consider up to 12 copies
number_of_copies <- seq(0, 12, 1)
# apply the function above
n_reads_w_cn_direct <-
  data.frame("CN" = number_of_copies,
             "n.reads" = map_int(
               number_of_copies,
               ~ count_reads_with_cn(blast_df_direct, cn = .)
             ))

#### now do different kind of filtering/counting using reverse reads ####
# these are the reads after the 1st filtering by length
reads_path <- "../results/reads/76595_D_mh/reads_filtered.fasta"
read_lengths <-
  Biostrings::width(Biostrings::readDNAStringSet(reads_path))

reads_len_df <-
  tibble("subject" = sub(
    "^(.*?) runid=.*",
    "\\1",
    names(Biostrings::readDNAStringSet(reads_path))
  ),
  "read.len" = read_lengths)

# filter reverse reads and
# join with reads lengths
blast_df_reverse <- 
  blast_df %>% 
  filter(orient == "reverse") %>% 
  left_join(reads_len_df, by = "subject")

# function to get the counts
count_reads_with_cn_reverse <- function(df, cn = 0) {
  # only for reverse hits!
  df %>%
    mutate(keep = (read.len - end.red) > (1820 + 3450 * cn)) %>%
    filter(keep) %>% 
    nrow()
}

# apply it
n_reads_w_cn_reverse <-
  data.frame("CN" = number_of_copies,
             "n.reads" = map_int(
               number_of_copies,
               ~ count_reads_with_cn_reverse(blast_df_reverse, cn = .)
             ))

n_reads_w_cn <- full_join(n_reads_w_cn_direct, n_reads_w_cn_reverse, by = "CN") %>% 
  mutate(n.reads.total = n.reads.x + n.reads.y)

#write_delim(n_reads_w_cn, file = "../results/tables/76595_D_mh/number_reads_containing_CN.tsv")

n_reads_w_cn
```


```{r}
n_reads_w_cn %>% 
  ggplot(aes(CN, n.reads.total)) +
  geom_col(fill="darkgreen", alpha = 0.5)
```



## Test of compatibility

New filtering of FR+RU+1820 and old FR green blast table

```{r}
get_multihits_ids <- function(df) {
  # df: filtered blast table
  # return: subject (read ids) containing multiple query hits
  df %>%
    group_by(subject) %>%
    count() %>%
    filter(n > 1) %>%
    pull(subject)
}

# here's the updated filtering function
filter_red_green <- function(df_red_ru, df_green) {
  # find read IDs containing multiple query hits
  reads_multiple_hits <- union(get_multihits_ids(df_red_ru),
                               get_multihits_ids(df_green))
  # filter out reads with multiple query hits
  # df_red_ru have differen column names!
  df_red_ru_filt <- df_red_ru %>%
    filter(!subject %in% reads_multiple_hits)
  df_green_filt <- df_green %>%
    filter(!subject %in% reads_multiple_hits)
  
  # Filter by orientation
  # Add distance between FRs
  df_joined <- full_join(df_red_ru_filt, df_green_filt, by = "subject") %>%
    filter(!is.na(query.x), !is.na(query.y), orient == orientation) %>%
    mutate(green.red.distance = end.red - start.subject,
           distance.btw.FR = if_else(green.red.distance < 0, 
                                     green.red.distance * -1, 
                                     green.red.distance * 1))
  return(df_joined)
}

blast_green <- parse_blast(file = "../results/tables/76595_D_mh/blast_green.tsv", "FR_green")
blast_red <- red_repunit_dir_dist
blast_red$query <- "FR_RU_filt"

# test the function
filter_red_green(blast_red, blast_green)
# it works!
```

## Calculations: way no. 1

reads that have passed through filtering step no. 3: R + IS + orient + 1820 incl.R

```{r}
library(tidyverse)

file_path <- "../results/tables/76595_D_mh/blast_joined_red_repunit_orient_len.tsv"

df_f3 <- read_tsv(file_path, show_col_types = F)

head(df_f3)
```

unique reads

```{r}
length(unique(df_f3$subject))
```

For the actual calculations see the Excel file

Binned reads: number of reads capable of containing certain number of blaSHV copies

```{r}
file <- "../results/tables/76595_D_mh/number_reads_containing_CN.tsv"

cn_bins <- read_delim(file, show_col_types = F) %>% 
  select(CN, n_reads_theoretical)

cn_bins
```

Now I need reads that actually contain 0, 1, 2 etc copies of blaSHV


```{r}
# the last table produced by the pipeline - with blaSHV counts
file <- "../results/tables/76595_D_mh/blaSHV_counts.tsv"
bla_cn <- read_delim(file, show_col_types = F) %>% 
  filter(!is.na(n.blaSHV.merged)) # why do you have NAs there?

unique(bla_cn$n.blaSHV.merged)
```


How many reads that were input of this step (i.e. from step 3) did not have any blaSHV?

```{r}
length(unique(df_f3$subject)) - length(unique(bla_cn$subject))
```

How many had different number of blaSHV copies?

```{r}
#cn0 <- length(unique(df_f3$subject)) - length(unique(bla_cn$subject))

bla_cn_freq <- 
  bla_cn %>% 
  group_by(n.blaSHV.merged) %>% 
  count(name = "counts") %>% 
  ungroup() %>% 
  #mutate(counts = counts + c(cn0, rep(0, 9))) %>% 
  rename("CN" = n.blaSHV.merged,
         "counts_obs" = counts)

bla_cn_freq
```

Calculation of the final table from the Excel file

```{r}
# total - n reads with 0 CN from the cn_bins table
total <- cn_bins %>% 
  filter(CN == 0) %>% 
  pull(n_reads_theoretical)

# find observed CN frequency
bla_cn_freq <- 
  bla_cn_freq %>% 
  mutate(freq_obs = counts_obs / total) # shouldn't it be sum(bla_counts_obs), not total?

# find frequency of reads that might contain certain CN
cn_bins <- 
  cn_bins %>% 
  mutate(freq_theoretical = n_reads_theoretical / total)

# adjust CN counts and then calculate frequency
bla_cn_freq <- 
  bla_cn_freq %>% 
  left_join(cn_bins, by = "CN") %>% 
  mutate(counts_corrected = counts_obs / freq_theoretical,
         freq_corrected = counts_corrected/sum(counts_corrected))

bla_cn_freq
```

```{r}
sum(bla_cn_freq$freq_corrected)
```


### Plot

```{r, fig.width=10, fig.height=10}
library(patchwork)

plot_line_full <- bla_cn_freq %>%
  select(CN, freq_obs, freq_corrected) %>%
  pivot_longer(cols = 2:3,
               names_to = "group",
               values_to = "freq") %>%
  ggplot(aes(CN, freq)) +
  geom_line(aes(color = group)) +
  scale_x_continuous(breaks = c(0:12)) +
  geom_rug(sides = "b", length = unit(0.03, "npc")) +
  scale_color_brewer(palette = "Dark2") +
  theme_bw() +
  theme(legend.position="top", legend.title = element_blank())

plot_line_part <- bla_cn_freq %>% 
  select(CN, freq_obs, freq_corrected) %>% 
  filter(CN >= 5) %>% 
  pivot_longer(cols = 2:3, names_to = "group", values_to = "freq") %>% 
  ggplot(aes(CN, freq)) + 
  geom_line(aes(color = group)) +
  scale_x_continuous(breaks = c(0:12)) +
  geom_rug(sides = "b", length = unit(0.03, "npc")) +
  scale_color_brewer(palette = "Dark2") +
  theme_bw() +
  theme(legend.position="top", legend.title = element_blank())

plot_line_log10 <- bla_cn_freq %>%
  select(CN, freq_obs, freq_corrected) %>%
  pivot_longer(cols = 2:3,
               names_to = "group",
               values_to = "freq") %>%
  ggplot(aes(CN, log10(freq))) +
  geom_line(aes(color = group)) +
  scale_x_continuous(breaks = c(0:12)) +
  geom_rug(sides = "b", length = unit(0.03, "npc")) +
  scale_color_brewer(palette = "Dark2") +
  theme_bw() +
  theme(legend.position="top", legend.title = element_blank())

(plot_line_full | plot_line_part) / plot_line_log10
```


```{r, fig.width=10}
plot_col_full <- bla_cn_freq %>% 
  select(CN, freq_obs, freq_corrected) %>% 
  pivot_longer(cols = 2:3, names_to = "group", values_to = "freq") %>% 
  ggplot(aes(CN, freq)) + 
  geom_col(aes(fill = group), position = "dodge") +
  scale_fill_brewer(palette = "Dark2") +
  scale_x_continuous(breaks = c(0:12)) +
  theme_bw() +
  geom_rug(sides = "b", length = unit(0.03, "npc")) + 
  theme(legend.position="top", legend.title = element_blank())

plot_col_part <- bla_cn_freq %>% 
  select(CN, freq_obs, freq_corrected) %>% 
  filter(CN >= 5) %>% 
  pivot_longer(cols = 2:3, names_to = "group", values_to = "freq") %>% 
  ggplot(aes(CN, freq)) + 
  geom_col(aes(fill = group), position = "dodge") +
  scale_fill_brewer(palette = "Dark2") +
  scale_x_continuous(breaks = c(0:12)) +
  theme_bw() +
  geom_rug(sides = "b", length = unit(0.03, "npc")) + 
  theme(legend.position="top", legend.title = element_blank())

(plot_col_full | plot_col_part)
```

## Calculations: way no. 2

We take into consideration only the reads that can contains the biggest CN of bla genes and calculate CN frequencies.
This new distribution should look similar to the one above.

```{r}
# read the table with reads filtered by red fr + rep.unit + orientation
table_path <- "../results/tables/76595_D_mh/blast_joined_red_repunit_orient_len.tsv"

blast_df <- read_tsv(
  file = table_path, 
  show_col_types = FALSE
  )

# filter direct hits
blast_df_direct <- 
  blast_df %>% 
  filter(orient == "direct")

#### now do different kind of filtering/counting using reverse reads ####
# these are the reads after the 1st filtering by length
reads_path <- "../results/reads/76595_D_mh/reads_filtered.fasta.gz"
read_lengths <-
  Biostrings::width(Biostrings::readDNAStringSet(reads_path))

reads_len_df <-
  tibble("subject" = sub(
    "^(.*?) runid=.*",
    "\\1",
    names(Biostrings::readDNAStringSet(reads_path))
  ),
  "read.len" = read_lengths)

# filter reverse reads and
# join with reads lengths
blast_df_reverse <- 
  blast_df %>% 
  filter(orient == "reverse") %>% 
  left_join(reads_len_df, by = "subject")

# the last table produced by the pipeline - with blaSHV counts
file <- "../results/tables/76595_D_mh/blaSHV_counts.tsv"
bla_cn <- read_delim(file, show_col_types = F) %>% 
  filter(!is.na(n.blaSHV.merged)) # why do you have NAs there?
```


```{r}
# this function returns a table of reads possibly containing 
# specified number of bla genes
# input: a table with direct hist and a table with reverse hits + corresponding reads lengths
reads_with_cn <- function(df_dir, df_rev, cn = 0) {
  min_len <- (1820 + 3450 * cn)
  bind_rows(
    # only for direct hits!
    df_dir %>%
      mutate(keep = end.red > min_len) %>%
      filter(keep),
    # only for reverse hits!
    df_rev %>%
      mutate(keep = (read.len - end.red) > min_len) %>%
      filter(keep)
  )
}

# biggest CN is 11
reads_cn11 <- reads_with_cn(blast_df_direct, blast_df_reverse, cn = 11) %>% 
  left_join(bla_cn, by = "subject") %>% 
  select(-c(keep, read.len))

# some reads do not contain blaSHV as expected
reads_cn11 %>% filter(is.na(n.blaSHV.merged)) %>% nrow()

# observed bla counts
reads_cn11 %>% 
  filter(!is.na(n.blaSHV.merged)) %>% 
  ggplot(aes(n.blaSHV.merged)) +
  geom_histogram(binwidth = 1) +
  scale_x_continuous(breaks = c(0:12)) +
  theme_bw() +
  geom_rug(sides = "b", length = unit(0.03, "npc"))
```

Get the actual frequencies

```{r}
reads_cn11_freq <- reads_cn11 %>% 
  filter(!is.na(n.blaSHV.merged)) %>% 
  select(subject, n.blaSHV.merged) %>% 
  group_by(n.blaSHV.merged) %>% 
  count() %>% 
  ungroup() %>% 
  mutate(freq_by_srhcn = n/sum(n)) %>% 
  rename("CN" = n.blaSHV.merged)

reads_cn11_freq %>% 
  ggplot(aes(CN, freq_by_srhcn)) +
  geom_line() +
  scale_x_continuous(breaks = c(0:12)) +
  theme_bw() +
  geom_rug(sides = "b", length = unit(0.03, "npc"))
  
```

Compare with the other way of calculating bla CN frequency

```{r}
bla_freq_2ways <-
  full_join(bla_cn_freq %>%
              select(CN, freq_obs, freq_corrected),
            reads_cn11_freq %>% 
              select(-n),
            by = "CN") %>% 
  mutate(freq_by_srhcn = map_dbl(freq_by_srhcn, ~replace(., is.na(.), 0)))

bla_freq_2ways %>% 
  pivot_longer(cols = 2:4,
               names_to = "group",
               values_to = "frequency") %>%
  ggplot(aes(CN, log10(frequency))) +
  geom_line(aes(color = group)) +
  scale_x_continuous(breaks = c(0:8, 11)) +
  geom_rug(sides = "b", length = unit(0.03, "npc")) +
  scale_color_brewer(palette = "Dark2") +
  theme_bw() +
  theme(legend.position="top", legend.title = element_blank())
```


```{r}
bla_freq_2ways
```

## Table of frequencies and plots

```{r}

config <- yaml::read_yaml("../workflow/config.yaml")
samples <- unlist(config$samples)

read_many_tables <- function(table_name) {
  out_df <- map_dfr(samples, function(x) {
    df <-
      read_tsv(paste0("../results/tables/", x, "/", table_name),
               show_col_types = F)
    df$sample <- x
    return(df)
  }) %>%
    mutate(replicate = str_split_i(sample, "_", i = 2),
           group = str_split_i(sample, "_", i = 3))
  
  return(out_df)
}

freq_df <- read_many_tables("frequencies.tsv") %>% 
  # add limits of detection
  mutate(detection_limit = 1/n.reads)

freq_df
```



```{r}
freq_df %>% 
  group_by(group) %>% 
  summarise(sum(freq_corrected))
  
```

## Average number of blaSHV

to compare with ddPCR

$$M_{gene} = \frac{\sum_{i=0}^n CN_{i}\frac{reads\_counts_{i}}{reads\_possible_{i}}}{\sum_{i=0}^n\frac{reads\_counts_{i}}{reads\_possible_{i}}}$$

```{r}
freq_df %>%
  group_by(group) %>%
  mutate(avg_gene_count = sum(CN * (counts_obs / freq_theoretical)) / sum((counts_obs /
                                                                             freq_theoretical))) %>%
  select(group, avg_gene_count) %>% 
  distinct() 
```

Seprate script for that?

## blaSHV hits between flanking regions

In the rule `filter_blaSHV_hits` I filter bla hits keeping only those that sit on the reads from FR+RU+RR filtering (including all distances and relative orientations).

Here, I will check how many of these bla SHV hits reside between the FR to exclude abberrant reads.

Table to analyse: `results/tables/{sample}/blast_joined.tsv` (reads from FR+RU+RR filtering)

```{r}
fr_ru_filt <- read_delim("../../results/tables/76595_D_10g/blast_joined.tsv", show_col_types = F)

fr_ru_filt %>% select(-c(mismatch, gaps, dist, identity))
```

```{r}
# max entries per read/subject
fr_ru_filt %>% count(subject) %>% arrange(n)
```


Column `green.red.distance` has been calculated by subtracting `start.subject` from `end.red`. Clearly, subject is FR green here.

Join this table with `filter_blaSHV_hits` output (it contains *bla*SHV hist) and find if their coordinates are between `start.subject` and `end.red` (take into account orientation).

If at least one *bla* hit per read will be found not between `start.subject` and `end.red` (reverse) or `end.subject` and `end.red`, such read should be considered aberrant and discarded from analysis.


```{r}
bla_filt <- read_delim("../../results/tables/76595_D_10g/blast_blaSHV_filtered.tsv", show_col_types = F)
bla_filt %>% count(subject)
```

```{r}
bla_filt %>% 
  filter(subject == "9a1dd6e5-a4e0-4cb4-975f-85e66575e0a1")
```

Let's find FRs coordinates for each read:

```{r}
# function to filter coords
is_between <-
  function(bla_start,
           bla_end,
           fr_start,
           fr_end) {
    # this is direct strand
    if (fr_start < fr_end) {
      # check if both ends of the gene are inside the FR coords
      if (between(bla_start, fr_start, fr_end) &
          between(bla_end, fr_start, fr_end)) {
        return(TRUE)
      } else {
        return(FALSE)
      }
    # this is reverse strand
    } else {
      # check the same condition but with FR ends swapped
      if (between(bla_start, fr_end, fr_start) &
          between(bla_end, fr_end, fr_start)) {
        return(TRUE)
      } else {
        return(FALSE)
      }
    }
  }

# apply is_between() to vectors/columns of a tibble
# this wrapper will return TRUE if any of the elements is FALSE, and FALSE if otherwise
any(!map2_lgl(c(10000, 17000, 29000), c(11000, 18000, 29500), ~ is_between(.x, .y, 5000, 30000)))

# apply the function to tibbles grouped by read ID
# one row - one read
# test this idea on a single row
fr_bla_test <- fr_ru_filt %>% 
  filter(subject == "9a1dd6e5-a4e0-4cb4-975f-85e66575e0a1") %>% 
  # this will copy values of FR coords across rows
  left_join(bla_filt, by = "subject") %>% 
  # BLA columns are prefixed by .y
  # start.subject.x and end.subject.x are the same across all rows now
  select(subject, start.subject.x, end.subject.x, end.red, start.subject.y, end.subject.y, orientation)
  
# apply the wrapper from above
# first two args must be BLA genes coords: start and end
any(!map2_lgl(
  fr_bla_test$start.subject.y,
  fr_bla_test$end.subject.y,
  ~ is_between(.x, .y, fr_bla_test$end.red[1], fr_bla_test$end.subject.x[1])
))

# make a solution for full table
genes_within_flanks <- function(read_id, fr_df, bla_df) {
  fr_bla_df <- fr_df %>%
    filter(subject == read_id) %>%
    # this will copy values of FR coords across rows
    left_join(bla_df, by = "subject") %>%
    # BLA columns are prefixed by .y
    # start.subject.x and end.subject.x are the same across all rows now
    select(
      subject,
      start.subject.x,
      end.subject.x,
      end.red,
      start.subject.y,
      end.subject.y,
      orientation
    )
  
  # FR coords are always the first elements of the end.red, end.subject.x columns
  answer <- any(
    !map2_lgl(
      fr_bla_df$start.subject.y,
      fr_bla_df$end.subject.y,
      ~ is_between(.x, .y, fr_bla_df$end.red[1], fr_bla_df$end.subject.x[1])
    )
  )
  
  return(answer)
}

# apply it to the whole table of this sample
map_vec(fr_ru_filt$subject, ~ genes_within_flanks(., fr_ru_filt, bla_filt)) %>% sum() # 4

# compare to the number of reads in the full table
nrow(fr_ru_filt) # 1840

(4/1840)*100
```


### Counts of abberant reads per sample (table)

Table and plots FYI

This filtering step should be implemented in the pipeline before the *blaSHV* counting is made.

Go to `final_cnv_plots.qmd`


